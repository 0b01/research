{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- By: Ashutosh Singh\n",
    "- Email: singh.ashu@gmail.com\n",
    "- Reference: Advances in Financial Machine Learning, Marcos Lopez De Prado, pg 59\n",
    "\n",
    "\n",
    "# Sample Weights\n",
    "\n",
    "This chapter handles the challenge of sampling observations (with replacement) when they are not IID (independent and identically distributed). This is especially hard in financial data sets which are rarely IID. In the framework espoused by MLDP in AFML, observations are labeled using triple-barrier method. Therein, each label has a start time (given by the index) and an end time.  The end time corresponds to the time when one of the barriers is touched. Consider a hypothetical example of four labels - A, B, C and D with their start and end times.\n",
    "\n",
    "A was generated at $t_1$ and triggered on $t_8$\n",
    "\n",
    "B was generated at $t_3$ and triggered on $t_6$\n",
    "\n",
    "C was generated on $t_7$ and triggered on $t_9$\n",
    "\n",
    "D was generated on $t_10$ and triggered on $t_12$\n",
    "\n",
    "\n",
    "In this case we see that A used information about returns on $[t_1,t_8]$ to generate label-endtime which overlaps with $[t_3, t_6]$ which was used by B and C, however D didn't use any returns information which was used by to label other samples. \n",
    "\n",
    "## Concurrency in labels\n",
    "\n",
    "We say that labels $y_i$ and $y_j$ are concurrent at $t$ if they are a function of at least one common return at $r_{t-1,t}$. In the example above, in terms of concurrency label D is the cleanest as it doesn't use any piece of information from other labels, while A has most overlap as it uses information from both B and C. It is desirable to use a data set that has least amount of overlap to train an algorithm.   \n",
    "\n",
    "We can measure average label uniqueness (or non-overlap) using get_av_uniqueness_from_tripple_barrier function from mlfinlab package. \n",
    "\n",
    "## Sampling with replacement  \n",
    "Bagging algorithms resort to sampling with replacement (or bootstrapping) but when observations overlap with one another then bootstrapping is susceptible to creating samples which have redundancy. This makes the algorithms that use bootstrapping such as random forest inefficient because in-bag observations to be very similar to the out-of-bag ones, inflating the accuracy of out-of-bag accuracy.\n",
    "\n",
    "## Sequenctial bootstrap process\n",
    "In the first draw, an observation is drawn from the uniform distribution. For the second draw, the sequential bootstrap (SB) reduces the probability of the observation that was drawn earlier from being drawn again. This process continues until the required number of draws are made. To implement this scheme, we first need to determine all the bars that a label (of an observation) uses. We compute a binary matrix that has bars on one axis and the labels on the other (this is called indicator matrix). This matrix is then used to compute the the average uniqueness of each observation. \n",
    "\n",
    "The sequentially bootstrap process iteratively selects observations while adjusting the draw probabilities of each observation at each step of the loop.\n",
    "\n",
    "## Notebook\n",
    "In this notebook we provide the answers to the questions at the back of the Chapter 4.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlfinlab.filters import filters\n",
    "from mlfinlab.labeling import labeling\n",
    "from mlfinlab.util import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlfinlab.sampling import concurrent\n",
    "from mlfinlab.sampling import bootstrapping\n",
    "from mlfinlab.util import multiprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 In Chapter 3. we denoted as t1 a pandas series of timestamps where the first barrier was touched, and the index was the timestamp of the observation. This was the output of the getEvents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 (a) Compute a t1 series on dollar bars derived from e-mini S&P 500 futures tick data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in data\n",
    "# data = pd.read_csv('official_data/dollar_bars.csv', nrows=40000)\n",
    "data = pd.read_csv('../Sample-Data/dollar_bars.csv')\n",
    "\n",
    "data.index = pd.to_datetime(data['date_time'])\n",
    "data = data.drop('date_time', axis=1)\n",
    "close_prices = data['close']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(close_prices.head())\n",
    "print(close_prices.describe())\n",
    "print('\\nNo of NANs: {:}'.format(close_prices.isna().sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute daily volatility\n",
    "vol = utils.get_daily_vol(close=close_prices, lookback=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply Symmetric CUSUM Filter and get timestamps for events\n",
    "# Note: Only the CUSUM filter needs a point estimate for volatility\n",
    "cusum_events = filters.cusum_filter(close_prices, threshold=vol.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute vertical barrier\n",
    "vertical_barriers = labeling.add_vertical_barrier(cusum_events, close_prices, num_days=1)\n",
    "vertical_barriers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "triple_barrier_events = labeling.get_events(close=close_prices,\n",
    "                                               t_events=cusum_events,\n",
    "                                               pt_sl=[1, 1],\n",
    "                                               target=vol,\n",
    "                                               min_ret=0.01,\n",
    "                                               num_threads=1,\n",
    "                                               vertical_barrier_times=vertical_barriers,\n",
    "                                               side_prediction=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "triple_barrier_events.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# triple_barrier_events"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 (b) Apply the function mpNumCoEvents to compute the number of overlapping outcomes at each point in time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlfinlab.sampling import concurrent\n",
    "from mlfinlab.util import multiprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_threads = 1\n",
    "num_conc_events = multiprocess.mp_pandas_obj(concurrent.num_concurrent_events, ('molecule', triple_barrier_events.index), num_threads, \n",
    "                                            close_series_index=close_prices.index, label_endtime=triple_barrier_events['t1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eliminate the duplicates\n",
    "num_conc_events = num_conc_events.loc[~num_conc_events.index.duplicated(keep='last')]\n",
    "\n",
    "# reindex based on the close prices\n",
    "num_conc_events = num_conc_events.reindex(close_prices.index).fillna(0)\n",
    "len(num_conc_events)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 (c) Plot the time-series of the number of concurrent labels on the primary axis, and the time series of exponentially weighted moving standard deviation of returns on the secondary axis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_df = (pd.DataFrame()\n",
    "              .assign(vol=vol,\n",
    "                     num_conc_events=num_conc_events)\n",
    "              .drop_duplicates().dropna()\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display_df.plot()\n",
    "display_df[['vol', 'num_conc_events']].plot(secondary_y='vol', figsize=(10,8))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 (d) Produce a scatterplot of the number of concurrent labels (x-axis) and the exponentially weighted moving standard deviation of returns (y-axis). Can you appreciate the relationship?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_df.plot.scatter(x='num_conc_events', y='vol', figsize=(10, 8))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(x=display_df['num_conc_events'], y=display_df['vol'], color='r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try polyfit\n",
    "x = display_df['num_conc_events']\n",
    "y = display_df['vol']\n",
    "z = np.polyfit(x, y, 2)\n",
    "p = np.poly1d(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xp = np.linspace(0, max(x)+1, 100)\n",
    "_ = plt.plot(x, y, '.', xp, p(xp), '-')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Using thefunction mpSampleTW, compute the average uniqueness of each label. What is the first-order serial correlation, AR(1), of this time series? Is it statistically significant? Why? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = multiprocess.mp_pandas_obj(concurrent._get_average_uniqueness, ('molecule', triple_barrier_events.index), num_threads, \n",
    "                                 label_endtime=triple_barrier_events['t1'], num_conc_events=num_conc_events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ACF plot\n",
    "pd.plotting.autocorrelation_plot(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.subplot(211)\n",
    "plot_acf(out, ax=plt.gca(), lags=5)\n",
    "plt.subplot(212)\n",
    "plot_pacf(out, ax=plt.gca(), lags=5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*The ACF chart shows the auocorrelation of average uniqueness of labels. The fact that the series is statistically significant at lags 1 and 2 indicate that uniqueness persists over time.  4.1.(c) shows that number of concurrent events are mostly zero except when volatility spikes. When the number of concurrent events is zero, then uniqueness is high. This means that we can expect autocorrelation at some level. Here it is at lags 1 and 2.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Fit a random forest to a financial data set where the average uniqueness is de minimis   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in data\n",
    "# data = pd.read_csv('official_data/dollar_bars.csv', nrows=40000)\n",
    "data = pd.read_csv('../Sample-Data/dollar_bars.csv')\n",
    "\n",
    "data.index = pd.to_datetime(data['date_time'])\n",
    "data = data.drop('date_time', axis=1)\n",
    "data = data.loc['2015-02-03':'2015-08-31']\n",
    "close_prices = data['close']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 (a) What is the mean out-of-bag accuracy?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Define RSI "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute RSI\n",
    "def relative_strength_index(df, n):\n",
    "        \"\"\"Calculate Relative Strength Index(RSI) for given data.\n",
    "        https://github.com/Crypto-toolbox/pandas-technical-indicators/blob/master/technical_indicators.py\n",
    "        \n",
    "        :param df: pandas.DataFrame\n",
    "        :param n: \n",
    "        :return: pandas.DataFrame\n",
    "        \"\"\"\n",
    "        i = 0\n",
    "        UpI = [0]\n",
    "        DoI = [0]\n",
    "        while i + 1 <= df.index[-1]:\n",
    "            UpMove = df.loc[i + 1, 'high'] - df.loc[i, 'high']\n",
    "            DoMove = df.loc[i, 'low'] - df.loc[i + 1, 'low']\n",
    "            if UpMove > DoMove and UpMove > 0:\n",
    "                UpD = UpMove\n",
    "            else:\n",
    "                UpD = 0\n",
    "            UpI.append(UpD)\n",
    "            if DoMove > UpMove and DoMove > 0:\n",
    "                DoD = DoMove\n",
    "            else:\n",
    "                DoD = 0\n",
    "            DoI.append(DoD)\n",
    "            i = i + 1\n",
    "        UpI = pd.Series(UpI)\n",
    "        DoI = pd.Series(DoI)\n",
    "        PosDI = pd.Series(UpI.ewm(span=n, min_periods=n).mean())\n",
    "        NegDI = pd.Series(DoI.ewm(span=n, min_periods=n).mean())\n",
    "        RSI = pd.Series(round(PosDI * 100. / (PosDI + NegDI)), name='RSI_' + str(n))\n",
    "        # df = df.join(RSI)\n",
    "        return RSI\n",
    "\n",
    "def get_rsi(data, window=14):\n",
    "    df = data.copy(deep=True).reset_index()\n",
    "    rsi = relative_strength_index(df, window)\n",
    "    rsi_df = pd.Series(data=rsi.values, index=data.index)\n",
    "    return rsi_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### define Bollinger bands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bbands(close_prices, window, no_of_stdev):\n",
    "    rolling_mean = close_prices.ewm(span=window).mean()\n",
    "    rolling_std = close_prices.ewm(span=window).std()\n",
    "\n",
    "    upper_band = rolling_mean + (rolling_std * no_of_stdev)\n",
    "    lower_band = rolling_mean - (rolling_std * no_of_stdev)\n",
    "\n",
    "    return rolling_mean, upper_band, lower_band"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute bands\n",
    "window = 50\n",
    "data['avg'], data['upper'], data['lower'] = bbands(data['close'], window, no_of_stdev=1.5)\n",
    "data.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute RSI\n",
    "rsi_df = get_rsi(data, window=14)\n",
    "data['rsi'] = pd.Series(data=rsi_df.values, index=data.index)\n",
    "\n",
    "# Drop the NaN values from our data set\n",
    "data.dropna(axis=0, how='any', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute sides\n",
    "data['side'] = np.nan \n",
    "\n",
    "long_signals = (data['close'] <= data['lower']) \n",
    "short_signals = (data['close'] >= data['upper']) \n",
    "\n",
    "data.loc[long_signals, 'side'] = 1\n",
    "data.loc[short_signals, 'side'] = -1\n",
    "\n",
    "print(data.side.value_counts())\n",
    "\n",
    "# Remove Look ahead bias by lagging the signal\n",
    "data['side'] = data['side'].shift(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the raw data\n",
    "raw_data = data.copy()\n",
    "\n",
    "# Drop the NaN values from our data set\n",
    "data.dropna(axis=0, how='any', inplace=True)\n",
    "print(data.side.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute daily volatility\n",
    "daily_vol = utils.get_daily_vol(close=data['close'], lookback=50)\n",
    "\n",
    "# Apply Symmetric CUSUM Filter and get timestamps for events\n",
    "# Note: Only the CUSUM filter needs a point estimate for volatility\n",
    "cusum_events = filters.cusum_filter(data['close'], threshold=daily_vol['2011-09-01':'2018-01-01'].mean() * 0.1)\n",
    "\n",
    "# Compute vertical barrier\n",
    "vertical_barriers = labeling.add_vertical_barrier(t_events=cusum_events, close=data['close'], num_days=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_sl = [0, 2]\n",
    "min_ret = 0.0005\n",
    "triple_barrier_events = labeling.get_events(close=data['close'],\n",
    "                                            t_events=cusum_events,\n",
    "                                            pt_sl=pt_sl,\n",
    "                                            target=daily_vol,\n",
    "                                            min_ret=min_ret,\n",
    "                                            num_threads=2,\n",
    "                                            vertical_barrier_times=vertical_barriers,\n",
    "                                            side_prediction=data['side'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Averge uniqueness\n",
    "avg_uniqueness = concurrent.get_av_uniqueness_from_tripple_barrier(triple_barrier_events, close_prices, num_threads=1)\n",
    "print(avg_uniqueness.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = labeling.get_bins(triple_barrier_events, data['close'])\n",
    "labels.side.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log Returns\n",
    "raw_data['log_ret'] = np.log(raw_data['close']).diff()\n",
    "\n",
    "# Momentum\n",
    "raw_data['mom1'] = raw_data['close'].pct_change(periods=1)\n",
    "raw_data['mom2'] = raw_data['close'].pct_change(periods=2)\n",
    "raw_data['mom3'] = raw_data['close'].pct_change(periods=3)\n",
    "raw_data['mom4'] = raw_data['close'].pct_change(periods=4)\n",
    "raw_data['mom5'] = raw_data['close'].pct_change(periods=5)\n",
    "\n",
    "# Volatility\n",
    "window_stdev = 50\n",
    "raw_data['volatility'] = raw_data['log_ret'].rolling(window=window_stdev, min_periods=window_stdev, center=False).std()\n",
    "\n",
    "# Serial Correlation (Takes about 4 minutes)\n",
    "window_autocorr = 50\n",
    "\n",
    "raw_data['autocorr_1'] = raw_data['log_ret'].rolling(window=window_autocorr, min_periods=window_autocorr, center=False).apply(lambda x: x.autocorr(lag=1), raw=False)\n",
    "raw_data['autocorr_2'] = raw_data['log_ret'].rolling(window=window_autocorr, min_periods=window_autocorr, center=False).apply(lambda x: x.autocorr(lag=2), raw=False)\n",
    "raw_data['autocorr_3'] = raw_data['log_ret'].rolling(window=window_autocorr, min_periods=window_autocorr, center=False).apply(lambda x: x.autocorr(lag=3), raw=False)\n",
    "raw_data['autocorr_4'] = raw_data['log_ret'].rolling(window=window_autocorr, min_periods=window_autocorr, center=False).apply(lambda x: x.autocorr(lag=4), raw=False)\n",
    "raw_data['autocorr_5'] = raw_data['log_ret'].rolling(window=window_autocorr, min_periods=window_autocorr, center=False).apply(lambda x: x.autocorr(lag=5), raw=False)\n",
    "\n",
    "# Get the various log -t returns\n",
    "raw_data['log_t1'] = raw_data['log_ret'].shift(1)\n",
    "raw_data['log_t2'] = raw_data['log_ret'].shift(2)\n",
    "raw_data['log_t3'] = raw_data['log_ret'].shift(3)\n",
    "raw_data['log_t4'] = raw_data['log_ret'].shift(4)\n",
    "raw_data['log_t5'] = raw_data['log_ret'].shift(5)\n",
    "\n",
    "# Add fast and slow moving averages\n",
    "fast_window = 7\n",
    "slow_window = 15\n",
    "\n",
    "raw_data['fast_mavg'] = raw_data['close'].rolling(window=fast_window, min_periods=fast_window, center=False).mean()\n",
    "raw_data['slow_mavg'] = raw_data['close'].rolling(window=slow_window, min_periods=slow_window, center=False).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add Trending signals\n",
    "raw_data['sma'] = np.nan\n",
    "\n",
    "long_signals = raw_data['fast_mavg'] >= raw_data['slow_mavg']\n",
    "short_signals = raw_data['fast_mavg'] < raw_data['slow_mavg']\n",
    "raw_data.loc[long_signals, 'sma'] = 1\n",
    "raw_data.loc[short_signals, 'sma'] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re compute sides\n",
    "raw_data['side'] = np.nan\n",
    "\n",
    "long_signals = raw_data['close'] <= raw_data['lower'] \n",
    "short_signals = raw_data['close'] >= raw_data['upper'] \n",
    "\n",
    "raw_data.loc[long_signals, 'side'] = 1\n",
    "raw_data.loc[short_signals, 'side'] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove look ahead bias\n",
    "raw_data = raw_data.shift(1)\n",
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now get the data at the specified events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get features at event dates\n",
    "X = raw_data.loc[labels.index, :]\n",
    "\n",
    "# Drop unwanted columns\n",
    "X.drop(['avg', 'upper', 'lower', 'open', 'high', 'low', 'close', 'cum_vol', 'cum_dollar', 'cum_ticks','fast_mavg', 'slow_mavg',], axis=1, inplace=True)\n",
    "\n",
    "y = labels['bin']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training, validation and test sets\n",
    "X_training_test = X\n",
    "y_training_test = y\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_training_test, y_training_test, test_size=0.2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.concat([y_train, X_train], axis=1, join='inner')\n",
    "train_df['bin'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Note that true positives (1) are a less than 25% of the false positives (0).  We would want to rebalance the class weights to pay more attention to true positives (and less to false positives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training data\n",
    "y_train = train_df['bin']\n",
    "X_train= train_df.loc[:, train_df.columns != 'bin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract parameters\n",
    "n_estimator = 100\n",
    "depth = 5\n",
    "c_random_state = 42\n",
    "print(n_estimator, depth, c_random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Model\n",
    "rf = RandomForestClassifier(max_depth=depth, n_estimators=n_estimator, oob_score=True,\n",
    "                            criterion='entropy', random_state=c_random_state)\n",
    "rf.fit(X_train, y_train.values.ravel())\n",
    "print(\"Out-of-bag Accuracy (OOB Score): {:.6f}\".format(rf.oob_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### *The out of bag accuracy in a data-set that has low uniqueness is very high (81%) ... commenting on observations with low uniquness, section 4.5 of AFML, page 63 states, \"random sampling will make out-of-bag examples very similar to in-the-bag ones, the OOB accuracy would be grossly inflated\"*  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 (b) what is the mean accuracy of k-fold cross-validation (without shuffling) on the same dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# k-fold\n",
    "no_of_folds = 5\n",
    "kfold = KFold(shuffle=False, random_state=1, n_splits=no_of_folds)\n",
    "print(kfold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_array = np.zeros(no_of_folds)\n",
    "i = 0\n",
    "for train_index, test_index in kfold.split(X_training_test):\n",
    "    # print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    rf.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "    y_pred_rf = rf.predict_proba(X_test)[:, 1]\n",
    "    y_pred = rf.predict(X_test)\n",
    "    accuracy_array[i] = accuracy_score(y_test, y_pred)\n",
    "    i += 1\n",
    "    # print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy_array)\n",
    "print(\"Mean KFold accuracy: {:.6f}\".format(np.mean(accuracy_array)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### *The mean accuracy from KFold is 79% - 2 percentatge point lower than OOB accuracy score. The OOB score is more biased because in case of sampling with replacement, there is higher redundancy within the in-the-bag observations. This in turn causes overestimation of accuracy.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4 Modify the code in Section 4.7 to apply an exponential time-decay factor   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Snippet 4.11 Implementation of time-decay factors\n",
    "def get_time_decay(tw, clf_last_w=1.):\n",
    "    # apply piecewise-linear decay to observed uniqueness (tw)\n",
    "    # newest observation gets weight=1, oldest observation gets weight=clf_last_w\n",
    "    clf_w = tw.sort_index().cumsum()\n",
    "    if clf_last_w >= 0:\n",
    "        slope = (1. - clf_last_w) / clf_w.iloc[-1]\n",
    "    else:\n",
    "        slope = 1. /((clf_last_w + 1) * clf_w.iloc[-1])\n",
    "    \n",
    "    const = 1. - slope * clf_w.iloc[-1]\n",
    "    clf_w = const + slope * clf_w\n",
    "    clf_w[clf_w < 0] = 0\n",
    "    print(\"Constant: {:.6f}, Slope: {:.6f}\".format(const, slope))\n",
    "    return clf_w\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implementation of exponential time-decay factors\n",
    "def get_time_decay_exp_old(tw, decay_rate=1.0, percent_of_zero_wts=0.):\n",
    "    clf_w = tw.sort_index().cumsum()\n",
    "    last_value = clf_w.iloc[-1]\n",
    "\n",
    "    # create the output weights array\n",
    "    out_wts = np.zeros(len(clf_w))\n",
    "    for i in np.arange(len(clf_w)):\n",
    "        if i < int(round(len(clf_w) * percent_of_zero_wts)):\n",
    "            out_wts[i] = 0\n",
    "        else:\n",
    "            out_wts[i] = np.exp((decay_rate - 1.) * (last_value - clf_w[i]))        \n",
    "    return out_wts\n",
    "\n",
    "def get_time_decay_exp(tw, decay_rate=1.0, percent_of_zero_wts=0.):\n",
    "    clf_w = tw.sort_index().cumsum()\n",
    "    last_value = clf_w.iloc[-1]\n",
    "\n",
    "    # create the output weights array\n",
    "    out_wts = [0. if i < int(round(len(clf_w) * percent_of_zero_wts)) else np.exp((decay_rate - 1.) * (last_value - clf_w[i])) for i in np.arange(len(clf_w))]\n",
    "    return np.asarray(out_wts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decay_p1 = get_time_decay(out, 1.)\n",
    "decay_p75 = get_time_decay(out, .75)\n",
    "decay_p5 = get_time_decay(out, .5)\n",
    "decay_pm25 = get_time_decay(out, -.25)\n",
    "decay_pm5 = get_time_decay(out, -0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decay_factor_linear_df = (pd.DataFrame(index=out.index)\n",
    "                          .assign(\n",
    "                              decay_p1=decay_p1,\n",
    "                              decay_p75=decay_p75,\n",
    "                              decay_p5=decay_p5,\n",
    "                              decay_pm25=decay_pm25,\n",
    "                              decay_pm5=decay_pm5\n",
    "                              )\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decay_factor_linear_df.plot(figsize=(12,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percent_of_zero_wts = 0.0\n",
    "decay_rate = 0.94 \n",
    "decay_exp_p99 = get_time_decay_exp(out, decay_rate=0.99, percent_of_zero_wts=percent_of_zero_wts)\n",
    "decay_exp_p94 = get_time_decay_exp(out, decay_rate=0.94, percent_of_zero_wts=percent_of_zero_wts)\n",
    "decay_exp_p100 = get_time_decay_exp(out, decay_rate=1.0, percent_of_zero_wts=percent_of_zero_wts)\n",
    "decay_exp_p99_20 = get_time_decay_exp(out, decay_rate=0.99, percent_of_zero_wts=.2)\n",
    "decay_exp_p94_20 = get_time_decay_exp(out, decay_rate=0.94, percent_of_zero_wts=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decay_factor_exp_df = (pd.DataFrame(index=out.index)\n",
    "                       .assign(\n",
    "                              decay_p99=decay_exp_p99,\n",
    "                              decay_p94=decay_exp_p94,\n",
    "                              decay_p100=decay_exp_p100,\n",
    "                              decay_pm25=decay_exp_p99_20,\n",
    "                              decay_pm5=decay_exp_p94_20\n",
    "                              )\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decay_factor_exp_df.plot(figsize=(12,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.5 Consider you have applied meta-labels to events determined by a trend-following model. Suppose that two-thirds of the labels are 0 and one third of the labels are 1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['bin'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training data\n",
    "y_train = train_df['bin']\n",
    "X_train= train_df.loc[:, train_df.columns != 'bin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract parameters\n",
    "n_estimator = 100\n",
    "depth = 5\n",
    "c_random_state = 42\n",
    "print(n_estimator, depth, c_random_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5.a What happens if you fit a classfier without balancing class weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### *Fit the random forest classifier and compute the performance metrics* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Model\n",
    "rf = RandomForestClassifier(max_depth=depth, n_estimators=n_estimator, oob_score=True,\n",
    "                            criterion='entropy', random_state=c_random_state)\n",
    "print(rf)\n",
    "rf.fit(X_train, y_train.values.ravel())\n",
    "print(\"Out-of-bag Accuracy (OOB Score): {:.6f}\".format(rf.oob_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance Metrics\n",
    "y_pred_rf = rf.predict_proba(X_train)[:, 1]\n",
    "y_pred = rf.predict(X_train)\n",
    "fpr_rf, tpr_rf, _ = roc_curve(y_train, y_pred_rf)\n",
    "print(classification_report(y_train, y_pred))\n",
    "\n",
    "print(\"Confusion Matrix\")\n",
    "print(confusion_matrix(y_train, y_pred))\n",
    "\n",
    "print('')\n",
    "print(\"Accuracy\")\n",
    "print(accuracy_score(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### *Although the accuracy is very high (84%), the recall of 1 (or true positive) is 17%. Recall is the fraction of the true positives that have been correctly picked. The confusion matrix says that TN or C(0,0) is 218 - 218 were true 0, with no mistakes in labeling FN or C(1,0) was zero. TP is C(1,1). Only 8 of the 48 were correctly labeled as 1.* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Meta-label\n",
    "# Performance Metrics\n",
    "y_pred_rf = rf.predict_proba(X_test)[:, 1]\n",
    "y_pred = rf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"Confusion Matrix\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print('')\n",
    "print(\"Accuracy\")\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### *When evaluating the out-of-sample data, the accuracy falls to 67%, the recall of 1 (or true positive) falls to 11%. Only 2 of the 19 labels were correctly identified.* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5.b A label 1 means true positive, and a label 0 means false positive. By applying balanced class weights, we are forcing the classifer to pay more attention to the true positives, and less attention to the false positives. Why does that make sense?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*We would like the classifier to learn how to pick true positives and it can do that better when there are more observations to learn from.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5.c What is the distribution of the predicted labels. before and after applying balanced class weights?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Model\n",
    "rf = RandomForestClassifier(max_depth=depth, n_estimators=n_estimator, oob_score=True,\n",
    "                            class_weight='balanced_subsample', criterion='entropy', \n",
    "                            random_state=c_random_state)\n",
    "print(rf)\n",
    "rf.fit(X_train, y_train.values.ravel())\n",
    "print(\"Out-of-bag Accuracy (OOB Score): {:.6f}\".format(rf.oob_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training data\n",
    "y_train = train_df['bin']\n",
    "X_train= train_df.loc[:, train_df.columns != 'bin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.fit(X_train, y_train.values.ravel())\n",
    "print(\"Out-of-bag Accuracy (OOB Score): {:.6f}\".format(rf.oob_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance Metrics\n",
    "y_pred_rf = rf.predict_proba(X_train)[:, 1]\n",
    "y_pred = rf.predict(X_train)\n",
    "fpr_rf, tpr_rf, _ = roc_curve(y_train, y_pred_rf)\n",
    "print(classification_report(y_train, y_pred))\n",
    "\n",
    "print(\"Confusion Matrix\")\n",
    "print(confusion_matrix(y_train, y_pred))\n",
    "\n",
    "print('')\n",
    "print(\"Accuracy\")\n",
    "print(accuracy_score(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Meta-label\n",
    "# Performance Metrics\n",
    "y_pred_rf = rf.predict_proba(X_test)[:, 1]\n",
    "y_pred = rf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"Confusion Matrix\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print('')\n",
    "print(\"Accuracy\")\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### *In a balanced out-of-sample test, the recall of true positives increases to 26% from 11% - a 136% increase.* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.6 Update the draw probabilities for the final draw in Section 4.5.3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Snippet 4.3\n",
    "def get_ind_matrix(bar_ix, t1):\n",
    "    # get indicator matrix\n",
    "    ind_m = pd.DataFrame(0, index=bar_ix, columns=range(t1.shape[0]))\n",
    "    for i, (t0, t1) in enumerate(t1.iteritems()):\n",
    "        ind_m.loc[t0:t1, i] = 1\n",
    "    return ind_m\n",
    "\n",
    "\n",
    "def get_ind_mat_average_uniqueness(ind_mat):\n",
    "    \"\"\"\n",
    "    Snippet 4.4. page 65, Compute Average Uniqueness\n",
    "    Average uniqueness from indicator matrix\n",
    "\n",
    "    :param ind_mat: (pd.Dataframe) indicator binary matrix\n",
    "    :return: (float) average uniqueness\n",
    "    \"\"\"\n",
    "    conc = ind_mat.sum(axis=1)  # concurrency\n",
    "    unique = ind_mat.div(conc, axis=0)\n",
    "    avg_unique = unique[unique > 0].mean()  # average uniqueness\n",
    "    return avg_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set-up\n",
    "tl = pd.Series([2, 3, 5], index=[0, 2, 4])  # t0, t1 for each feature obs\n",
    "bar_ix = range(tl.max() + 1)\n",
    "# ind_m = bootstrapping.get_ind_matrix(bar_ix, tl)\n",
    "ind_m = get_ind_matrix(bar_ix, tl)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_u = pd.Series()\n",
    "phi = [1, 2]\n",
    "\n",
    "for i in ind_m:\n",
    "    ind_m_ = ind_m[phi + [i]]\n",
    "    # avg_u.loc[i] = bootstrapping.get_ind_mat_average_uniqueness(ind_m_).iloc[-1]\n",
    "    avg_u.loc[i] = get_ind_mat_average_uniqueness(ind_m_).iloc[-1]\n",
    "\n",
    "prob = avg_u / avg_u.sum()\n",
    "print('Prob: {}\\n'.format(prob))\n",
    "phi += [np.random.choice(ind_m.columns, p=prob)]\n",
    "print('Phi: {}'.format(phi))\n",
    "print('-----------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.7 Section 4.5.3, suppose that number 2 is picked again in the second draw. What would the updated probabilities for the third draw?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set-up\n",
    "tl = pd.Series([2, 3, 5], index=[0, 2, 4])  # t0, t1 for each feature obs\n",
    "bar_ix = range(tl.max() + 1)\n",
    "ind_m = get_ind_matrix(bar_ix, tl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.7\n",
    "phi = [1, 1]\n",
    "for i in ind_m:\n",
    "    ind_m_ = ind_m[phi + [i]]\n",
    "    avg_u.loc[i] = get_ind_mat_average_uniqueness(ind_m_).iloc[-1]\n",
    "\n",
    "prob = avg_u / avg_u.sum()\n",
    "print('Prob: {}\\n'.format(prob))\n",
    "phi += [np.random.choice(ind_m.columns, p=prob)]\n",
    "print('Phi: {}'.format(phi))\n",
    "print('-----------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EF3M Implementation Testing\n",
    "## Abstract\n",
    "This notebook tests the implementation of the EF3M algorithm using synthetic data as well as the example used in the source literature. This notebook is intended to provide convincing evidence of the accuracy of this EF3M implementation.\n",
    "## Introduction\n",
    "The Exact Fit of the first 3 Moments (EF3M) algorithm allows the parameters of a mixture of Gaussian distributions to be estimated given the first 5 moments of the mixture distribution, as well as the assumption that the mixture distribution is composed of a number of Gaussian distributions. The algorithm, its development, and its original implementation are described in López de Prado, M. and M. Foreman (2014): \"A mixture of Gaussians approach to mathematical portfolio oversight: The EF3M algorithm.\" _Quantitative Finance_, Vol. 14, No. 5, pp. 913-930. The implementation tested here can be found in the `EF3M\\ef3m.py` module located in this directory of the repository. Three test cases are presented. First, the example from the algorithm's source paper is presented to confirm that we can replicate the results of literature. Second, a user-defined mixture of 2 Gaussian distributions is generated and the EF3M implementation is tasked to recover the original mixture parameters from the raw moments of the synthetic distribution. Third, the second case is executed using a series of randomly chosen parameters from which to compose the mixture distribution. The notebook user can alter this at will but should keep in mind that running a large number of trials with hundreds or thousands of rounds each will take hours or days even using the current multiprocessing implementation.\n",
    "## Conclusion\n",
    "The tests run in this notebook conclude that using the EF3M algorithm to generate a series of estimates followed by a kernel density estimation to determine the most likely value for each parameter from said series results in a recovery of the original mixture parameters to within a very close tolerance.\n",
    "## Next Steps\n",
    "The implementation tested here supports only distributions assumed to be composed of two Gaussian distributions. A natural next step would be to extend this algorithm to $n$ Gaussian distributions. Though this implementation will likely take exponentially more computational power, the utility in being able to fit more complex distributions would prove useful in more advanced cases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from dask.diagnostics import ProgressBar\n",
    "ProgressBar().register()\n",
    "from scipy.stats import gaussian_kde\n",
    "\n",
    "# import function from our custom module\n",
    "from EF3M.ef3m import M2N, rawMoment\n",
    "\n",
    "# helper function for finding most likely parameter estimates\n",
    "def most_likely_parameters(data, ignore_columns='error', res=10_000):\n",
    "    # Determines the most likely parameter estimate using a KDE\n",
    "    # :param data: (pandas.DataFrame) contains parameter estimates from all runs\n",
    "    # :param ignore_columns: (string, list) column or columns to exclude from analysis\n",
    "    # :param res: (int) resolution of the kernel density estimate\n",
    "    # :return: (dict) labels and most likely estimates for parameters\n",
    "    # ===================================================\n",
    "    df = data.copy()\n",
    "    if isinstance(ignore_columns, str):\n",
    "        ignore_columns = [ignore_columns]\n",
    "    columns = [c for c in df.columns if c not in ignore_columns]\n",
    "    d_results = {}\n",
    "    for col in columns:\n",
    "        x_range = np.linspace(df[col].min(), df[col].max(), num=res)\n",
    "        kde = gaussian_kde(df[col].to_numpy())\n",
    "        y_kde = kde.evaluate(x_range)\n",
    "        top_value = round(x_range[np.argmax(y_kde)], 5)\n",
    "        d_results[col] = top_value\n",
    "        fig, ax = plt.subplots(figsize=(10,10))\n",
    "        ax.plot(x_range, y_kde)\n",
    "        ax = sns.distplot(df[col].to_numpy(), ax=ax, bins=100)\n",
    "        plt.show()\n",
    "    return d_results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case 1: Example data from source literature\n",
    "López de Prado, M. and M. Foreman (2014): \"A mixture of Gaussians approach to mathematical portfolio oversight: The EF3M algorithm.\" _Quantitative Finance_, Vol. 14, No. 5, pp. 913-930."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# moments and parameters from source literature\n",
    "moments = [0.7, 2.6, 0.4, 25, -59.8]  # about the origin\n",
    "epsilon = 10**-5\n",
    "factor = 5  # this is the 'lambda' referred to in the paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_runs = 20_000\n",
    "\n",
    "m2n = M2N(moments)\n",
    "df2 = m2n.mpFit(moments, epsilon=10**-6, factor=5, n_runs=n_runs, variant=2, maxIter=10_000_000)\n",
    "df2 = df2.sort_values('error')\n",
    "\n",
    "results = most_likely_parameters(df2)\n",
    "\n",
    "print(df2.head())\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case 2: User-defined single example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing algorithm for raw moments\n",
    "central_moments = [0, 2.11, -4.3740, 30.8037, -153.5857]\n",
    "dist_mean = 0.7\n",
    "# central_moments: the first n (1...n) central moments as a list\n",
    "# dist_mean: the mean of the distribution\n",
    "# ====================================\n",
    "# the first n (0...n) raw moments (about the origin) will be \n",
    "# calculated and returned\n",
    "raw_moments = [dist_mean]\n",
    "central_moments = [1] + central_moments  # add the zeroth moment\n",
    "for n in range(2, len(central_moments)):\n",
    "    moment_n_parts = []\n",
    "    for k in range(n+1):\n",
    "        sum_part = comb(n, k) * central_moments[k] * dist_mean**(n-k)\n",
    "        moment_n_parts.append(sum_part)\n",
    "    moment_n = sum(moment_n_parts)\n",
    "    raw_moments.append(moment_n)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case 3: Series of randomly generated examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trend Following Strategy\n",
    "\n",
    "This notebook answers question 3.4 form the text book Advances in Financial Machine Learning.\n",
    "\n",
    "3.4 Develop a trend-following strategy based on a popular technical analysis statistic (e.g., crossing moving averages). For each observation, the model suggests a side, but not a size of the bet.\n",
    "\n",
    "* (a) Derive meta-labels for ptSl = [1, 2] and t1 where numDays = 1. Use as trgt the daily standard deviation as computed by Snippet 3.1.\n",
    "* (b) Train a random forest to decide whether to trade or not. Note: The decision is whether to trade or not, {0,1}, since the underlying model (the crossing moving average) has decided the side, {-1, 1}.\n",
    "\n",
    "I took some liberties by extending the features to which I use to build the meta model. I also add some performance metrics at the end. \n",
    "\n",
    "In conclusion: Meta Labeling works, SMA strategies suck."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyfolio as pf\n",
    "import timeit\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve, classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.utils import resample\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from mlfinlab.corefns.core_functions import CoreFunctions\n",
    "from mlfinlab.util.utils import get_daily_returns\n",
    "from mlfinlab.fracdiff.fracdiff import frac_diff_ffd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in Data\n",
    "We are using the dollar bars based off of the high quality HFT data we purchased. There is a sample of bars available in this branch as well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in data\n",
    "data = pd.read_csv('official_data/dollar_bars.csv')\n",
    "data.index = pd.to_datetime(data['date_time'])\n",
    "data = data.drop('date_time', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data['2011-09-01':]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Fit a Primary Model: Trend Following\n",
    "Based on the simple moving average cross-over strategy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fast_window = 20\n",
    "slow_window = 50\n",
    "\n",
    "fast_window = 50\n",
    "slow_window = 200\n",
    "\n",
    "\n",
    "data['fast_mavg'] = data['close'].rolling(window=fast_window, min_periods=fast_window, center=False).mean()\n",
    "data['slow_mavg'] = data['close'].rolling(window=slow_window, min_periods=slow_window, center=False).mean()\n",
    "data.head()\n",
    "\n",
    "# Compute sides\n",
    "data['side'] = np.nan\n",
    "\n",
    "long_signals = data['fast_mavg'] >= data['slow_mavg']\n",
    "short_signals = data['fast_mavg'] < data['slow_mavg']\n",
    "data.loc[long_signals, 'side'] = 1\n",
    "data.loc[short_signals, 'side'] = -1\n",
    "\n",
    "# Remove Look ahead biase by lagging the signal\n",
    "data['side'] = data['side'].shift(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the raw data\n",
    "raw_data = data.copy()\n",
    "\n",
    "# Drop the NaN values from our data set\n",
    "data.dropna(axis=0, how='any', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1.0    47376\n",
       "-1.0    36372\n",
       "Name: side, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['side'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter Events: CUSUM Filter\n",
    "Predict what will happen when a CUSUM event is triggered. Use the signal from the MAvg Strategy to determine the side of the bet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating daily volatility for dynamic thresholds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 356/83746 [00:00<00:23, 3552.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying Symmetric CUSUM filter.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 83746/83746 [00:16<00:00, 5000.16it/s]\n"
     ]
    }
   ],
   "source": [
    "# Compute daily volatility\n",
    "daily_vol = CoreFunctions.get_daily_vol(close=data['close'], lookback=50)\n",
    "\n",
    "# Apply Symmetric CUSUM Filter and get timestamps for events\n",
    "# Note: Only the CUSUM filter needs a point estimate for volatility\n",
    "cusum_events = CoreFunctions.get_t_events(data['close'], threshold=daily_vol.mean()*0.5)\n",
    "\n",
    "# Compute vertical barrier\n",
    "vertical_barriers = CoreFunctions.add_vertical_barrier(t_events=cusum_events, close=data['close'], num_days=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ariadne/Desktop/Research Project/research/Chapter3/mlfinlab/corefns/core_functions.py:205: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n",
      "  target = target.loc[t_events]\n",
      "2019-03-17 01:00:37.735956 100.0% apply_pt_sl_on_t1 done after 0.46 minutes. Remaining 0.0 minutes.\n"
     ]
    }
   ],
   "source": [
    "pt_sl = [1, 2]\n",
    "min_ret = 0.005\n",
    "triple_barrier_events = CoreFunctions.get_events(close=data['close'],\n",
    "                                  t_events=cusum_events,\n",
    "                                  pt_sl=pt_sl,\n",
    "                                  target=daily_vol,\n",
    "                                  min_ret=min_ret,\n",
    "                                  num_threads=2,\n",
    "                                  vertical_barrier_times=vertical_barriers,\n",
    "                                  side=data['side'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.0    4546\n",
       " 1.0    3624\n",
       "Name: side, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = CoreFunctions.get_bins(triple_barrier_events, data['close'])\n",
    "labels.side.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Results of Primary Model:\n",
    "What is the accuracy of predictions from the primary model (i.e., if the sec- ondary model does not filter the bets)? What are the precision, recall, and F1-scores?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      4904\n",
      "           1       0.40      1.00      0.57      3266\n",
      "\n",
      "   micro avg       0.40      0.40      0.40      8170\n",
      "   macro avg       0.20      0.50      0.29      8170\n",
      "weighted avg       0.16      0.40      0.23      8170\n",
      "\n",
      "Confusion Matrix\n",
      "[[   0 4904]\n",
      " [   0 3266]]\n",
      "\n",
      "Accuracy\n",
      "0.3997552019583843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ariadne/anaconda3/envs/mlfinlab/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "primary_forecast = pd.DataFrame(labels['bin'])\n",
    "primary_forecast['pred'] = 1\n",
    "primary_forecast.columns = ['actual', 'pred']\n",
    "\n",
    "# Performance Metrics\n",
    "actual = primary_forecast['actual']\n",
    "pred = primary_forecast['pred']\n",
    "print(classification_report(y_true=actual, y_pred=pred))\n",
    "\n",
    "print(\"Confusion Matrix\")\n",
    "print(confusion_matrix(actual, pred))\n",
    "\n",
    "print('')\n",
    "print(\"Accuracy\")\n",
    "print(accuracy_score(actual, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Fit a Meta Model\n",
    "Train a random forest to decide whether to trade or not (i.e 1 or 0 respectively) since the earlier model has decided the side (-1 or 1)\n",
    "\n",
    "Create the following features: \n",
    "* Volatility\n",
    "* Serial Correlation\n",
    "* The returns at the different lags from the serial correlation\n",
    "* The sides from the SMavg Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>cum_vol</th>\n",
       "      <th>cum_dollar</th>\n",
       "      <th>cum_ticks</th>\n",
       "      <th>fast_mavg</th>\n",
       "      <th>slow_mavg</th>\n",
       "      <th>side</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date_time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2011-09-01 06:08:14.750</th>\n",
       "      <td>1217.50</td>\n",
       "      <td>1224.50</td>\n",
       "      <td>1216.5</td>\n",
       "      <td>1220.00</td>\n",
       "      <td>57388</td>\n",
       "      <td>70028257.0</td>\n",
       "      <td>19018</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-09-01 07:48:09.398</th>\n",
       "      <td>1220.00</td>\n",
       "      <td>1224.50</td>\n",
       "      <td>1215.5</td>\n",
       "      <td>1215.75</td>\n",
       "      <td>57394</td>\n",
       "      <td>70005670.5</td>\n",
       "      <td>20160</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-09-01 09:13:14.311</th>\n",
       "      <td>1215.75</td>\n",
       "      <td>1216.50</td>\n",
       "      <td>1209.5</td>\n",
       "      <td>1210.00</td>\n",
       "      <td>57691</td>\n",
       "      <td>70000560.5</td>\n",
       "      <td>21107</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-09-01 10:51:49.085</th>\n",
       "      <td>1210.00</td>\n",
       "      <td>1213.50</td>\n",
       "      <td>1208.5</td>\n",
       "      <td>1212.50</td>\n",
       "      <td>57801</td>\n",
       "      <td>70003237.5</td>\n",
       "      <td>17728</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-09-01 12:23:59.756</th>\n",
       "      <td>1212.50</td>\n",
       "      <td>1216.75</td>\n",
       "      <td>1210.5</td>\n",
       "      <td>1215.75</td>\n",
       "      <td>57656</td>\n",
       "      <td>70000722.0</td>\n",
       "      <td>19398</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            open     high     low    close  cum_vol  \\\n",
       "date_time                                                             \n",
       "2011-09-01 06:08:14.750  1217.50  1224.50  1216.5  1220.00    57388   \n",
       "2011-09-01 07:48:09.398  1220.00  1224.50  1215.5  1215.75    57394   \n",
       "2011-09-01 09:13:14.311  1215.75  1216.50  1209.5  1210.00    57691   \n",
       "2011-09-01 10:51:49.085  1210.00  1213.50  1208.5  1212.50    57801   \n",
       "2011-09-01 12:23:59.756  1212.50  1216.75  1210.5  1215.75    57656   \n",
       "\n",
       "                         cum_dollar  cum_ticks  fast_mavg  slow_mavg  side  \n",
       "date_time                                                                   \n",
       "2011-09-01 06:08:14.750  70028257.0      19018        NaN        NaN   NaN  \n",
       "2011-09-01 07:48:09.398  70005670.5      20160        NaN        NaN   NaN  \n",
       "2011-09-01 09:13:14.311  70000560.5      21107        NaN        NaN   NaN  \n",
       "2011-09-01 10:51:49.085  70003237.5      17728        NaN        NaN   NaN  \n",
       "2011-09-01 12:23:59.756  70000722.0      19398        NaN        NaN   NaN  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log Returns\n",
    "raw_data['log_ret'] = np.log(raw_data['close']).diff()\n",
    "\n",
    "# Momentum\n",
    "raw_data['mom1'] = raw_data['close'].pct_change(periods=1)\n",
    "raw_data['mom2'] = raw_data['close'].pct_change(periods=2)\n",
    "raw_data['mom3'] = raw_data['close'].pct_change(periods=3)\n",
    "raw_data['mom4'] = raw_data['close'].pct_change(periods=4)\n",
    "raw_data['mom5'] = raw_data['close'].pct_change(periods=5)\n",
    "\n",
    "# Volatility\n",
    "raw_data['volatility_50'] = raw_data['log_ret'].rolling(window=50, min_periods=50, center=False).std()\n",
    "raw_data['volatility_31'] = raw_data['log_ret'].rolling(window=31, min_periods=31, center=False).std()\n",
    "raw_data['volatility_15'] = raw_data['log_ret'].rolling(window=15, min_periods=15, center=False).std()\n",
    "\n",
    "# Serial Correlation (Takes about 4 minutes)\n",
    "window_autocorr = 50\n",
    "\n",
    "raw_data['autocorr_1'] = raw_data['log_ret'].rolling(window=window_autocorr, min_periods=window_autocorr, center=False).apply(lambda x: x.autocorr(lag=1), raw=False)\n",
    "raw_data['autocorr_2'] = raw_data['log_ret'].rolling(window=window_autocorr, min_periods=window_autocorr, center=False).apply(lambda x: x.autocorr(lag=2), raw=False)\n",
    "raw_data['autocorr_3'] = raw_data['log_ret'].rolling(window=window_autocorr, min_periods=window_autocorr, center=False).apply(lambda x: x.autocorr(lag=3), raw=False)\n",
    "raw_data['autocorr_4'] = raw_data['log_ret'].rolling(window=window_autocorr, min_periods=window_autocorr, center=False).apply(lambda x: x.autocorr(lag=4), raw=False)\n",
    "raw_data['autocorr_5'] = raw_data['log_ret'].rolling(window=window_autocorr, min_periods=window_autocorr, center=False).apply(lambda x: x.autocorr(lag=5), raw=False)\n",
    "\n",
    "# Get the various log -t returns\n",
    "raw_data['log_t1'] = raw_data['log_ret'].shift(1)\n",
    "raw_data['log_t2'] = raw_data['log_ret'].shift(2)\n",
    "raw_data['log_t3'] = raw_data['log_ret'].shift(3)\n",
    "raw_data['log_t4'] = raw_data['log_ret'].shift(4)\n",
    "raw_data['log_t5'] = raw_data['log_ret'].shift(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re compute sides\n",
    "raw_data['side'] = np.nan\n",
    "\n",
    "long_signals = raw_data['fast_mavg'] >= raw_data['slow_mavg']\n",
    "short_signals = raw_data['fast_mavg'] < raw_data['slow_mavg']\n",
    "raw_data.loc[long_signals, 'side'] = 1\n",
    "raw_data.loc[short_signals, 'side'] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove look ahead bias\n",
    "raw_data = raw_data.shift(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now get the data at the specified events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get features at event dates\n",
    "X = raw_data.loc[labels.index, :]\n",
    "\n",
    "# Drop unwanted columns\n",
    "X.drop(['open', 'high', 'low', 'close', 'cum_vol', 'cum_dollar', 'cum_ticks','fast_mavg', 'slow_mavg',], axis=1, inplace=True)\n",
    "\n",
    "y = labels['bin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Balance classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training, validation and test sets\n",
    "X_training_validation = X['2011-09-01':'2018-01-01']\n",
    "y_training_validation = y['2011-09-01':'2018-01-01']\n",
    "X_train, X_validate, y_train, y_validate = train_test_split(X_training_validation, y_training_validation, test_size=0.15, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.concat([y_train, X_train], axis=1, join='inner')\n",
    "train_df['bin'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upsample the training data to have a 50 - 50 split\n",
    "# https://elitedatascience.com/imbalanced-classes\n",
    "majority = train_df[train_df['bin'] == 0]\n",
    "minority = train_df[train_df['bin'] == 1]\n",
    "\n",
    "new_minority = resample(minority, \n",
    "                   replace=True,     # sample with replacement\n",
    "                   n_samples=majority.shape[0],    # to match majority class\n",
    "                   random_state=42)\n",
    "\n",
    "train_df = pd.concat([majority, new_minority])\n",
    "train_df = shuffle(train_df, random_state=42)\n",
    "\n",
    "train_df['bin'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training data\n",
    "y_train = train_df['bin']\n",
    "X_train= train_df.loc[:, train_df.columns != 'bin']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'max_depth':[2, 3, 4, 5, 7],\n",
    "              'n_estimators':[1, 10, 25, 50, 100, 256, 512],\n",
    "              'random_state':[42]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(criterion='entropy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = GridSearchCV(rf, parameters, cv=4, scoring='roc_auc', n_jobs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.cv_results_['mean_test_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Model\n",
    "n_estimator = clf.best_params_['n_estimators']\n",
    "c_random_state = 42\n",
    "depth = clf.best_params_['max_depth']\n",
    "\n",
    "rf = RandomForestClassifier(max_depth=depth, n_estimators=n_estimator,\n",
    "                            criterion='entropy', random_state=c_random_state)\n",
    "\n",
    "rf.fit(X_train, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance Metrics\n",
    "y_pred_rf = clf.predict_proba(X_train)[:, 1]\n",
    "y_pred = clf.predict(X_train)\n",
    "fpr_rf, tpr_rf, _ = roc_curve(y_train, y_pred_rf)\n",
    "print(classification_report(y_train, y_pred))\n",
    "\n",
    "print(\"Confusion Matrix\")\n",
    "print(confusion_matrix(y_train, y_pred))\n",
    "\n",
    "print('')\n",
    "print(\"Accuracy\")\n",
    "print(accuracy_score(y_train, y_pred))\n",
    "\n",
    "plt.figure(1)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(fpr_rf, tpr_rf, label='RF')\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('ROC curve')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance Metrics\n",
    "y_pred_rf = clf.predict_proba(X_validate)[:, 1]\n",
    "y_pred = clf.predict(X_validate)\n",
    "fpr_rf, tpr_rf, _ = roc_curve(y_validate, y_pred_rf)\n",
    "print(classification_report(y_validate, y_pred))\n",
    "\n",
    "print(\"Confusion Matrix\")\n",
    "print(confusion_matrix(y_validate, y_pred))\n",
    "\n",
    "print('')\n",
    "print(\"Accuracy\")\n",
    "print(accuracy_score(y_validate, y_pred))\n",
    "\n",
    "plt.figure(1)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(fpr_rf, tpr_rf, label='RF')\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('ROC curve')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Importance\n",
    "title = 'Feature Importance:'\n",
    "figsize = (15, 5)\n",
    "\n",
    "feat_imp = pd.DataFrame({'Importance':rf.feature_importances_})    \n",
    "feat_imp['feature'] = X.columns\n",
    "feat_imp.sort_values(by='Importance', ascending=False, inplace=True)\n",
    "feat_imp = feat_imp\n",
    "\n",
    "feat_imp.sort_values(by='Importance', inplace=True)\n",
    "feat_imp = feat_imp.set_index('feature', drop=True)\n",
    "feat_imp.plot.barh(title=title, figsize=figsize)\n",
    "plt.xlabel('Feature Importance Score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Performance Tear Sheets (In-sample)\n",
    "\n",
    "### Without Meta Labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_dates = X_validate.index\n",
    "base_rets = labels.loc[valid_dates, 'ret']\n",
    "primary_model_rets = get_daily_returns(base_rets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set-up the function to extract the KPIs from pyfolio\n",
    "perf_func = pf.timeseries.perf_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the statistics in a dataframe\n",
    "perf_stats_all = perf_func(returns=primary_model_rets, \n",
    "                           factor_returns=None, \n",
    "                           positions=None,\n",
    "                           transactions=None,\n",
    "                           turnover_denom=\"AGB\")\n",
    "perf_stats_df = pd.DataFrame(data=perf_stats_all, columns=['Primary Model'])\n",
    "\n",
    "pf.show_perf_stats(primary_model_rets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With Meta Labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_returns = labels.loc[valid_dates, 'ret'] * y_pred\n",
    "daily_meta_rets = get_daily_returns(meta_returns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the KPIs in a dataframe\n",
    "perf_stats_all = perf_func(returns=daily_meta_rets, \n",
    "                           factor_returns=None, \n",
    "                           positions=None,\n",
    "                           transactions=None,\n",
    "                           turnover_denom=\"AGB\")\n",
    "\n",
    "perf_stats_df['Meta Model'] = perf_stats_all\n",
    "\n",
    "pf.show_perf_stats(daily_meta_rets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Perform out-of-sample test\n",
    "### Meta Model Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extarct data for out-of-sample (OOS)\n",
    "X_oos = X['2018-01-02':]\n",
    "y_oos = y['2018-01-02':]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance Metrics\n",
    "y_pred_rf = clf.predict_proba(X_oos)[:, 1]\n",
    "y_pred = clf.predict(X_oos)\n",
    "fpr_rf, tpr_rf, _ = roc_curve(y_oos, y_pred_rf)\n",
    "print(classification_report(y_oos, y_pred))\n",
    "\n",
    "print(\"Confusion Matrix\")\n",
    "print(confusion_matrix(y_oos, y_pred))\n",
    "\n",
    "print('')\n",
    "print(\"Accuracy\")\n",
    "print(accuracy_score(y_oos, y_pred))\n",
    "\n",
    "plt.figure(1)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(fpr_rf, tpr_rf, label='RF')\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('ROC curve')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Primary Model (Test Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dates = X_oos.index\n",
    "\n",
    "# Downsample to daily\n",
    "prim_rets_test = labels.loc[test_dates, 'ret']\n",
    "daily_rets_prim = get_daily_returns(prim_rets_test)\n",
    "\n",
    "# Save the statistics in a dataframe\n",
    "perf_stats_all = perf_func(returns=daily_rets_prim, \n",
    "                           factor_returns=None, \n",
    "                           positions=None,\n",
    "                           transactions=None,\n",
    "                           turnover_denom=\"AGB\")\n",
    "\n",
    "perf_stats_df['Primary Model OOS'] = perf_stats_all\n",
    "\n",
    "# pf.create_returns_tear_sheet(labels.loc[test_dates, 'ret'], benchmark_rets=None)\n",
    "pf.show_perf_stats(daily_rets_prim)\n",
    "\n",
    "pf.create_returns_tear_sheet(daily_rets_prim, benchmark_rets=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Meta Model (Test Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_returns = labels.loc[test_dates, 'ret'] * y_pred\n",
    "daily_rets_meta = get_daily_returns(meta_returns)\n",
    "\n",
    "# save the KPIs in a dataframe\n",
    "perf_stats_all = perf_func(returns=daily_rets_meta, \n",
    "                           factor_returns=None, \n",
    "                           positions=None,\n",
    "                           transactions=None,\n",
    "                           turnover_denom=\"AGB\")\n",
    "\n",
    "perf_stats_df['Meta Model OOS'] = perf_stats_all\n",
    "\n",
    "pf.create_returns_tear_sheet(daily_rets_meta, benchmark_rets=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* By: Illya Barziy\n",
    "* Email: illyabarziy@gmail.com\n",
    "* Reference: __A Robust Estimator of the Efficient Frontier__ _by_ Marcos Lopez de Prado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Nested Clustered Optimization algorithm (NCO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This description and the realization of the algorithm is based on the paper by _Marcos Lopez de Prado_ __A Robust Estimator of the Efficient Frontier__  [available here](https://papers.ssrn.com/abstract_id=3469961)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convex optimization solutions in the problems of portfolio optimization tend to be unstable. The instability comes from two sources:\n",
    "- noise in the input variables\n",
    "- signal structure that magnifies the estimation errors in the input variables\n",
    "\n",
    "The NCO algorithm tackles both sources of instability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem Statement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Say, we have a system with $N$ random variables, the expected value of draws of the variables are $\\mu$ and the covariance matrix is $V$. We want to compute the vector $w$ that minimizes the variance of the system, where the variance is $w'Vw$, subject to $w'a$. Here $a$ characterizes the optimal solution. \n",
    "\n",
    "So, the problem is:\n",
    "\n",
    "$min_{w}\\frac{1}{2}w'Vw$\n",
    "\n",
    "$s.t.: w'a = 1 $\n",
    "\n",
    "In financial application, the optimal allocation $w^*$ known as the maximum Sharpe ratio, when $a = \\mu$ (as it maximizes $\\frac{w'\\mu}{\\sqrt{w'Vw}}$).\n",
    "\n",
    "The optimal allocation $w^*$ known as the minimum variance portfolio, when $a = 1_{N}$, where $1_{N}$ is the vector of ones of size $N$ (as it maximizes the $w'Vw$).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the convex optimization methods, the optimal solution to the problem is\n",
    "\n",
    "$w^* = \\frac{V^{-1}a}{a'V^{-1}a}$\n",
    "\n",
    "This is the Convex Optimization Solution (CVO)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the input varaibles $V$ and $a$ are typically unknown, the estimations are used, which leads to unstable solutions where a small change of inputs will cause bix changes of $w^*$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instability caused by noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a matrix of iid random observations $X$, of size $TxN$. The underlying process is generating the observations with zero mean and $\\sigma^2$ variance. \n",
    "\n",
    "The matrix $C = T^{-1}X'X$ has eigenvalues $\\lambda$ that asymptotically converge (as $N -> +\\infty$ and $T -> +\\infty$ with $1 < \\frac{T}{N} < +\\infty$) to the Marcenko-Pastur probability density function.\n",
    "\n",
    "$ f[\\lambda] =\n",
    "  \\begin{cases}\n",
    "    \\frac{T}{N}\\frac{\\sqrt{(\\lambda_+-\\lambda)(\\lambda-\\lambda_-)}}{2\\pi\\lambda\\sigma^2} & \\quad \\text{if } i \\in [\\lambda_-,\\lambda_+] \\text{,}\\\\\n",
    "    0  & \\quad \\text{if } i \\notin [\\lambda_-,\\lambda_+] \\text{.}\n",
    "  \\end{cases}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where the maximim expected eigenvalue is \n",
    "\n",
    "$\\lambda_+ = \\sigma^2(1 + \\sqrt{\\frac{N}{T}})^2$\n",
    "\n",
    "and the minimum expected eigenvalue is \n",
    "\n",
    "$\\lambda_- = \\sigma^2(1 - \\sqrt{\\frac{N}{T}})^2$\n",
    "\n",
    "When $\\sigma^2 = 1$, then $C$ is the correlation matrix associated with X."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Marcenko-Pastur distribution explains why empirical covariance matrixces contain substantial amounts of noise. \n",
    "\n",
    "In many practical applications, $\\frac{N}{T}->1$, thus the covariance's eigenvalues span a wide range $[\\lambda_-,\\lambda_+]$. Because $\\lambda_- -> 0$ as $\\frac{N}{T}->1$, the determinant of $V$ approaches zero and $V^{-1}$ cannot be estimated robustly, this is the source of unstable solutions $w^*$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The process of de-noising the covariance matrix that is used in the code examples in the end is described in a paper by _Potter M._, _J.P. Bouchaud_, _L. Laloux_ __“Financial applications of random matrix theory:\n",
    "Old laces and new pieces.”__  [available here](https://arxiv.org/abs/physics/0507111)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instability caused by signal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Certain covariance structures can make the optimal solution unstable. Looking at the correlation matrix between two variables:\n",
    "\n",
    "$C = \\begin{equation}\n",
    "  \\begin{bmatrix}\n",
    "    1 & \\rho \\\\\n",
    "    \\rho & 1 \n",
    "  \\end{bmatrix}\n",
    "\\end{equation}$\n",
    "\n",
    "Where the $\\rho$ is the correlation between their outcomes. Matrix $C$ can be diagonalized as $CW = W\\Lambda$, where"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\Lambda = \\begin{equation}\n",
    "  \\begin{bmatrix}\n",
    "    1 & +\\rho \\\\\n",
    "    1 & -\\rho \n",
    "  \\end{bmatrix}\n",
    "\\end{equation}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$W = \\begin{equation}\n",
    "  \\begin{bmatrix}\n",
    "    \\frac{1}{\\sqrt{2}} & \\frac{1}{\\sqrt{2}} \\\\\n",
    "    \\frac{1}{\\sqrt{2}} & -\\frac{1}{\\sqrt{2}} \n",
    "  \\end{bmatrix}\n",
    "\\end{equation}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The inverse of $C$ is\n",
    "\n",
    "$C^{-1}=W\\Lambda^{-1}W'=\\frac{1}{|C|} = \\begin{equation}\n",
    "  \\begin{bmatrix}\n",
    "    1 & -\\rho \\\\\n",
    "    -\\rho & 1 \n",
    "  \\end{bmatrix}\n",
    "\\end{equation}$\n",
    "\n",
    "Where $|C|$ is the determinant of $C$, $|C|=(1+\\rho)(1-\\rho)=1-\\rho^2$.\n",
    "\n",
    "We can see that more $\\rho$ derives from zero, the bigger one eigenvalue becomes relative to the other, causing the determinant of $C$ to approach zero, which makes the values of $C^{-1}$ explode."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the correlation matrix is an identity matrix, the eigenvalue function is a horizontal line. Outside that ideal case, at least one subset of variables exhibits greater correlation among themselves than to the rest, forming a cluster within the correlation matrix. \n",
    "\n",
    "When $K$ variables form a cluster, they are more heavily exposed to a common eigenvector, which implies that the associated eigenvalue explains a greater amount of variance. \n",
    "\n",
    "But because the trace of the correlation matrix is exactly $N$, that means that an eigenvalue can only increase at the expense of the other $K-1$ eigenvalues in that cluster, resulting in a condition number greater than 1. Consequently, the greater the intra-cluster correlation is, the higher the condition number becomes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### De-noising function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function provided below for de-noising the covariance works as follows:\n",
    "- The given covariance matrix is transformed to the correlation matrix.\n",
    "- The eigenvalues and eigenvectors of the correlation matrix are calculated.\n",
    "- Using the Kernel Density Estimate algorithm a kernel of the eigenvalues is estimated.\n",
    "- The Marcenko-Pastur pdf is fitted to the KDE estimate using the variance as the parameter for the optimization.\n",
    "- From the obtained Marcenko-Pastur distribuiton, the maximum theoretical eigenvalue is calculated using the formula from \"Instability caused by noise\" part.\n",
    "- The eigenvalues that are observed in the set above the theoretical value are all set to the average value.\n",
    "- The new set of eigenvalues with the set of eigenvectors is used to obtain the new de-noised correlation matrix.\n",
    "- The new correlation matrix is then transformed back to the new de-noised covariance matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is how the de-noising function can be used:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlfinlab as ml\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The de-noised covariance matrix is:\n",
      "[[ 0.01        0.00267029 -0.00133514]\n",
      " [ 0.00267029  0.04       -0.00438387]\n",
      " [-0.00133514 -0.00438387  0.01      ]]\n"
     ]
    }
   ],
   "source": [
    "# A class that has the de-noising function\n",
    "risk_estimators = ml.portfolio_optimization.RiskEstimators()\n",
    "\n",
    "# Covariance matrix to de-noise\n",
    "cov_matrix = np.array([[0.01, 0.002, -0.001],\n",
    "                       [0.002, 0.04, -0.006],\n",
    "                       [-0.001, -0.006, 0.01]])\n",
    "\n",
    "# Relation of number of observations T to the number of variables N\n",
    "tn_relation = 50\n",
    "\n",
    "# The bandwidth of the KDE kernel\n",
    "kde_bwidth = 0.25\n",
    "\n",
    "# Finding the de-noised covariance matrix\n",
    "cov_matrix_denoised = risk_estimators.de_noised_cov(cov_matrix, tn_relation, kde_bwidth)\n",
    "\n",
    "# Outputting the result\n",
    "print('The de-noised covariance matrix is:')\n",
    "print(cov_matrix_denoised)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the main diagonal hasn't changed, but the other covariances are different. This means that the algorithm has changed the eigenvalues of the correlation matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also functions to transform covariance matrix into correlation matrix and back are available:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The correlation matrix is:\n",
      "[[ 1.   0.1 -0.1]\n",
      " [ 0.1  1.  -0.3]\n",
      " [-0.1 -0.3  1. ]]\n",
      "The covariance matrix calculated back is:\n",
      "[[ 0.01   0.002 -0.001]\n",
      " [ 0.002  0.04  -0.006]\n",
      " [-0.001 -0.006  0.01 ]]\n",
      "Exactly the same as the original one:\n",
      "[[ 0.01   0.002 -0.001]\n",
      " [ 0.002  0.04  -0.006]\n",
      " [-0.001 -0.006  0.01 ]]\n"
     ]
    }
   ],
   "source": [
    "# Transforming our covariance matrix to a correlation matrix\n",
    "corr_matrix = risk_estimators.cov_to_corr(cov_matrix)\n",
    "\n",
    "# Outputting the result\n",
    "print('The correlation matrix is:')\n",
    "print(corr_matrix)\n",
    "\n",
    "# The standard deviation\n",
    "std = np.array([0.1,0.2,0.1])\n",
    "\n",
    "# And back to the covariance matrix\n",
    "cov_matrix_again = risk_estimators.corr_to_cov(corr_matrix, std)\n",
    "\n",
    "# Outputting the result\n",
    "print('The covariance matrix calculated back is:')\n",
    "print(cov_matrix_again)\n",
    "print('Exactly the same as the original one:')\n",
    "print(cov_matrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NCO and CVO functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The CVO solves the problem described in the \"Problem Statement\" part using the provided formula\n",
    "\n",
    "$w^* = \\frac{V^{-1}a}{a'V^{-1}a}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The NCO algorithm is following these steps:\n",
    "\n",
    "- Get the covariance matrix of the outcomes as an input (and the vector of means if the target is to maximize the Sharpe ratio).\n",
    "- Transform the covariance matrix to the correlation matrix and calculate the distance matrix based on it.\n",
    "- Cluster the covariance matrix into subsets of highly-correlated variables.\n",
    "- Compute the optimal weights allocation for every cluster (using the CVO).\n",
    "- Reduce the original covariance matrix to a reduced one - where each cluster is represented by a single variable.\n",
    "- Compute the optimal weights allocation for the reduced covariance matrix (using the CVO).\n",
    "- Compute the final allocations as a dot-product of the allocations between the clusters and inside the clusters.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is how the NCO and the CVO can be used:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The optimal weights with minimum variance using the NCO are:\n",
      "[[0.43875825]\n",
      " [0.09237016]\n",
      " [0.4688716 ]]\n"
     ]
    }
   ],
   "source": [
    "# A class that has the NCO and CVO functions\n",
    "nco = ml.portfolio_optimization.NCO()\n",
    "\n",
    "# Covariance matrix\n",
    "cov_matrix = np.array([[0.01, 0.002, -0.001],\n",
    "                       [0.002, 0.04, -0.006],\n",
    "                       [-0.001, -0.006, 0.01]])\n",
    "\n",
    "# Vector of ones (goal is minimizing the variance)\n",
    "mu_vec = np.array([1, 1, 1]).reshape(-1, 1)\n",
    "\n",
    "# Maximum number of clusters to use in the correlation matrix clustering\n",
    "max_num_clusters = 2\n",
    "\n",
    "# Finding the optimal weights using the NCO\n",
    "w_nco = nco.opt_port_nco(cov_matrix, mu_vec, max_num_clusters=max_num_clusters)\n",
    "\n",
    "# Outputting the result\n",
    "print('The optimal weights with minimum variance using the NCO are:')\n",
    "print(w_nco)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now using the simple CVO algorithm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The optimal weights with minimum variance using the CVO are:\n",
      "[[0.37686939]\n",
      " [0.14257228]\n",
      " [0.48055833]]\n"
     ]
    }
   ],
   "source": [
    "# Finding the optimal weights using the CVO\n",
    "w_cvo = nco.opt_port(cov_matrix, mu_vec)\n",
    "\n",
    "# Outputting the result\n",
    "print('The optimal weights with minimum variance using the CVO are:')\n",
    "print(w_cvo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results are different, so the NCO has clustered the correlation matrix. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MCOS function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Monte Carlo Optimization Selection (MCOS) algorithm calculates the NCO allocations and a simple optimal allocation for multiple simulated pairs of mean vector and the covariance matrix to determine the most robust method for weights allocations for a given pair of means vector and a covariance vector. Basically it will show if the NCO or the CVO method is more robust.\n",
    "\n",
    "However, the MCOS may support other optimization methods and compare their robustness.\n",
    "\n",
    "The steps of the MCOS algorithm are:\n",
    "- Get the covariance matrix and the means vector of the outcomes as an input (along with the simulation parameters to use).\n",
    "- Drawing the empirical covariance matrix and the empirical means vector based on the true ones.\n",
    "- If the kde_bwidth parameter is given, the empirical covariance matrix is de-noised.\n",
    "- Based on the min_var_portf parameter, either the minimum variance or the maximum Sharpe ratio is targeted in weights allocation.\n",
    "- Simple optimal allocation is applied to the empirical data to obtain the weights allocation.\n",
    "- NCO is applied to the empirical data to obtain the weights allocation.\n",
    "- Based on the original covariance matrix and the means vector a true optimal allocation is calculated.\n",
    "- For each weights estimation in a method, a standard deviation between the true weights and the obtained weights is calculated.\n",
    "- The error associated with each method is calculated as the mean of the standard deviation across all estimations for the method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is how the MCOS can be used:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The optimal weights with minimum variance using the NCO from simulations are:\n",
      "          0         1         2         3\n",
      "0  0.181431  0.326042  0.165669  0.326857\n",
      "1  0.221613  0.394977  0.204978  0.178432\n",
      "The optimal weights with minimum variance using the CVO from simulations are:\n",
      "          0         1         2         3\n",
      "0  0.165431  0.344039  0.168434  0.322096\n",
      "1  0.202771  0.427418  0.212893  0.156919\n"
     ]
    }
   ],
   "source": [
    "# Covariance matrix\n",
    "cov_mat = np.array([[1, 0.1, 0.2, 0.3],\n",
    "                    [0.1, 1, 0.1, 0.2],\n",
    "                    [0.2, 0.1, 1, 0.1],\n",
    "                    [0.3, 0.2, 0.1, 1]])\n",
    "\n",
    "# Vector of means\n",
    "mu_vec = np.array([0, 0.1, 0.2, 0.3])\n",
    "cov_mat = np.array([[1, 0.1, 0.2, 0.3],\n",
    "                    [0.1, 1, 0.1, 0.2],\n",
    "                    [0.2, 0.1, 1, 0.1],\n",
    "                    [0.3, 0.2, 0.1, 1]])\n",
    "\n",
    "# Number of observations to use to obtain empirical covariance matrix and the means vector\n",
    "num_obs = 100\n",
    "\n",
    "# Number of simulations to do in the MCOS\n",
    "num_sims = 2\n",
    "\n",
    "# The bandwidth of the KDE kernel.\n",
    "kde_bwidth = 0.25\n",
    "\n",
    "# Flag if the goal is the minimum variance\n",
    "min_var_portf = True\n",
    "\n",
    "# Flag if we want to use the Ledoit-Wolf shrinkage procedure\n",
    "lw_shrinkage = False\n",
    "\n",
    "# For the same result output\n",
    "np.random.seed(1)\n",
    "\n",
    "# Finding the optimal weights for minimum variance\n",
    "w_cvo, w_nco = nco.opt_port_mcos(mu_vec, cov_mat, num_obs, num_sims, kde_bwidth, min_var_portf, lw_shrinkage)\n",
    "\n",
    "# Outputting the result\n",
    "print('The optimal weights with minimum variance using the NCO from simulations are:')\n",
    "print(w_nco)\n",
    "print('The optimal weights with minimum variance using the CVO from simulations are:')\n",
    "print(w_cvo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the outputs can be analyzed based on the mean of the standard deviation with the true weight allocations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean of the standard deviation with the true weight for NCO is:\n",
      "0.0524762395749268\n",
      "The mean of the standard deviation with the true weight for CVO is:\n",
      "0.05839900155706323\n"
     ]
    }
   ],
   "source": [
    "# Finding the errors in estimations\n",
    "err_cvo, err_nco = nco.estim_errors_mcos(w_cvo, w_nco, mu_vec, cov_mat, min_var_portf)\n",
    "\n",
    "# Outputting the result\n",
    "print('The mean of the standard deviation with the true weight for NCO is:')\n",
    "print(err_nco)\n",
    "print('The mean of the standard deviation with the true weight for CVO is:')\n",
    "print(err_cvo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even on this small example, we can see that the NCO has performed better than the CVO method (the error measure is smaller)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample Data Generating function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can create a random vector of means and a random covariance matrix to properly test the algorithms described above. \n",
    "\n",
    "These created covariance matrix and vector of means have the characteristics of securities inside being grouped in clusters. The clusters pose a high correlation and also have different correlations between clusters in order to test the NCO and the MCOS algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is how the Sample Data Generating function can be used:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The generated vector of means is:\n",
      "[[-0.00089985]\n",
      " [ 0.2608328 ]\n",
      " [ 0.45695781]\n",
      " [ 0.0015997 ]]\n",
      "The generated covariance matrix is:\n",
      "       0      3      2      1\n",
      "0  0.090  0.000  0.000  0.027\n",
      "3  0.000  0.090  0.027  0.000\n",
      "2  0.000  0.027  0.090  0.000\n",
      "1  0.027  0.000  0.000  0.090\n"
     ]
    }
   ],
   "source": [
    "# Number of blocks to have in a modeled matrix\n",
    "num_blocks = 2\n",
    "\n",
    "# The size of each block in a modeled matrix\n",
    "block_size = 2\n",
    "\n",
    "# Correlation inside a block\n",
    "block_corr = 0.3\n",
    "\n",
    "# Correlation between the clusters\n",
    "std = 0.3\n",
    "\n",
    "# Finding the random vector of means and covariance matrix\n",
    "mu_vec, cov_matrix = nco.form_true_matrix(num_blocks, block_size, block_corr, std)\n",
    "\n",
    "# Outputting the result\n",
    "print('The generated vector of means is:')\n",
    "print(mu_vec)\n",
    "print('The generated covariance matrix is:')\n",
    "print(cov_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These covariance vector and matrix of means can be used to test the NCO and the CVO methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook describes the Nested Clustered Optimization (NCO) algorithm, the Monte Carlo Optimization Selection (MCOS) algorithm alongside with the De-noising algorithm and other helping functions. Also it shows how these can be used on some real examples.\n",
    "\n",
    "The algorithms and the descriptions are  were originally presented by _Marcos Lopez de Prado_ in the paper __A Robust Estimator of the Efficient Frontier__  [available here](https://papers.ssrn.com/abstract_id=3469961).\n",
    "\n",
    "Key takeaways from the notebook:\n",
    "- Convex optimization solutions in the problems of portfolio optimization tend to be unstable.\n",
    "- The instability comes from two sources\n",
    "  - Noise in the input variables\n",
    "  - Signal structure that magnifies the estimation errors in the input variables\n",
    "- The De-noising algorithm calculates the eigenvalues of the correlation matrix and eliminates those that are higher than the theoretically estimated ones, as they are caused by noise.\n",
    "- The Convex Optimization Solution (CVO) can either find optimal allocations for maximum Sharpe ratio or minimum variance.\n",
    "- The Nested Clustered Optimization (NCO) breaks the correlation function into clusters and applies CVO individually to each cluster as well as to the correlation matrix where each element represents the cluster.\n",
    "- The Monte Carlo Optimization Selection (MCOS) allows runnin optimization methods (in our case CVO and NCO) on multiple sets of empirical covariation matrixes and empirical vectors of means. It can show which method is more robust.\n",
    "- The Sample Data Generating function can be used to get a covariance matrix that has distinct clusters with correlations inside a cluster and different correlations between those clusters."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlfinlab",
   "language": "python",
   "name": "mlfinlab"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
